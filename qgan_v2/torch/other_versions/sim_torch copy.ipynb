{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748a6214",
   "metadata": {},
   "source": [
    "Cambios: \n",
    "    Optimizacion: \n",
    "        Uso de EstimatorV2 de qiskit_aer.primitive con backend_options especificos. Uso de Session y Estimator de qiskit_ibm_runtime para hardware real.\n",
    "        Backend configuration + load/save with pickle\n",
    "        Uso de metodos de gradientes de qiskit_algorithms.gradients.\n",
    "        Tipo de dato torch.float32 para tensores.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The Quantum Generative Adversarial Network (QGAN) [[1]](https://github.com/Qiskit/textbook/blob/main/notebooks/quantum-machine-learning/qgan.ipynb)  [[2]](https://arxiv.org/abs/1406.2661) we propose consists of two Quantum Neural Network (QNN) [[3]](https://qiskit-community.github.io/qiskit-machine-learning/tutorials/01_neural_networks.html): a generator and a discriminator. The generator is responsible for creating synthetic data samples. The discriminator evaluates the authenticity of the created samples by distinguishing between real and generated data. Through an adversarial training process, both networks continuously improve, leading to the generation of increasingly realistic data. \n",
    "This fully quantum approach benefits from the strengths of quantum state preparation and gradient calculation combined with classical optimizators [[4]](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
    "The data used to train the QGAN in this implementation is a probability distributions.\n",
    "\n",
    "This implementation uses aer_simulator_statevector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f07d8",
   "metadata": {},
   "source": [
    "## Implementation (statevector simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31245d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- INSTALATION INSTRUCTIONS ---#\n",
    "\n",
    "# For linux 64-bit systems,\n",
    "#uname -a\n",
    "\n",
    "# Conda quick installation\n",
    "#mkdir -p ~/miniconda3\n",
    "#wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
    "#bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
    "#rm ~/miniconda3/miniconda.sh\n",
    "\n",
    "# Create enviroment with conda\n",
    "#conda create -n myenv python=3.10\n",
    "#conda activate myenv\n",
    "#pip install qiskit==1.4.5 qiskit-machine-learning==0.8.4 'qiskit-machine-learning[sparse]' qiskit_aer qiskit_algorithms torch matplotlib pylatexenc ipykernel\n",
    "# IMPORTANT: Make sure you are on 3.10\n",
    "# May need to restart the kernel after instalation\n",
    "\n",
    "#--- Imports ---#\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.quantum_info import random_statevector, Statevector, SparsePauliOp\n",
    "from qiskit.circuit.library import RealAmplitudes, EfficientSU2\n",
    "from qiskit.primitives import StatevectorEstimator\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit import qpy\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN # Downgrade to qiskit 1.x so is compatible with qiskit-machine-learning 0.8.2\n",
    "from qiskit_machine_learning.gradients import ParamShiftEstimatorGradient, SPSAEstimatorGradient\n",
    "\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "from qiskit_aer.backends.backendconfiguration import AerBackendConfiguration\n",
    "from qiskit_aer.backends.backendproperties import AerBackendProperties\n",
    "from qiskit_aer.primitives import EstimatorV2 as EstimatorV2_sim\n",
    "\n",
    "from qiskit_ibm_runtime import EstimatorV2 as EstimatorV2_rh, QiskitRuntimeService, Session\n",
    "from qiskit_ibm_runtime.options import EstimatorOptions\n",
    "\n",
    "from qiskit_algorithms.gradients import ReverseEstimatorGradient\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import signal\n",
    "import datetime as dt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101a4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Configuration -#\n",
    "\n",
    "# Training configuration dict\n",
    "train_config = {\n",
    "    'execution_type': \"noisy_simulation\", #noiseless_simulation\n",
    "    'n_qubits': 4,\n",
    "    'seed': 2,\n",
    "    'id': None, # For different circuits or training parameters\n",
    "    'reset_data': False,\n",
    "\n",
    "    'create_circuits': False, # Create circuits manually or load from file\n",
    "    'gradient_method': \"REG\", # qiskit_algorithms.gradients For now: PSR, SPSA and REG\n",
    "    'max_iterations': 1000,\n",
    "    'gen_iterations': 1,\n",
    "    'disc_iterations': 1,\n",
    "    'save_loss_iterations': 10, # Calculate extra forward pass to save loss\n",
    "    'print_progress_iterations': 10,\n",
    "\n",
    "    'training_data_file': None, # Automatically created with manage_files function\n",
    "    'circuits_file': None, # Automatically created with manage_files function\n",
    "    'backend_file': None # Automatically created with manage_files function\n",
    "}\n",
    "\n",
    "# File management\n",
    "def manage_files(data_folder_name = 'data', implementation_name = 'fullyq_torch', execution_type_name = train_config['execution_type'], training_data_file_name = 'training_data', circuits_file_name = 'circuits', backend_file_name = 'backend'):\n",
    "    data_folder = data_folder_name + '/' + implementation_name + '/' + execution_type_name + '/' + 'q' + str(train_config['n_qubits']) + '/' + 'seed' + str(train_config['seed']) + '/'\n",
    "    if train_config['id'] is not None:\n",
    "        data_folder = data_folder + '/' + str(train_config['id']) + '/' \n",
    "    training_data_file = data_folder + training_data_file_name + '.pth'\n",
    "    circuits_file = data_folder + circuits_file_name + '.qpy'\n",
    "    backend_file = data_folder + backend_file_name + '.pkl'\n",
    "\n",
    "    # Create folders if they do not exist\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "\n",
    "    return training_data_file, circuits_file, backend_file\n",
    "\n",
    "if ((train_config['training_data_file'] is None) and (train_config['circuits_file'] is None) and (train_config['backend_file'] is None)):\n",
    "    train_config['training_data_file'], train_config['circuits_file'], train_config['backend_file'] = manage_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58895836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend data file not found. Resetting backend configuration.\n"
     ]
    }
   ],
   "source": [
    "#- Backend configuration -#\n",
    "backend_config = {\n",
    "    # Real backend\n",
    "    'name': \"ibm_basquecountry\",\n",
    "    'channel': \"ibm_quantum_platform\",\n",
    "\n",
    "    # Noisy backend\n",
    "    'reset_backend': False, # Get current backend state or load from file\n",
    "    'timestamp': dt.datetime(year=2025, month=12, day=5, hour = 10, tzinfo=dt.timezone.utc), # Get exact backend state, None to get current state (no he conseguido q funcione)\n",
    "\n",
    "    # Noiseless backend\n",
    "    'sim_options': {\n",
    "        'method': 'statevector',\n",
    "        #'device': 'GPU',\n",
    "        'precision': 'single',       # Significant speedup \n",
    "        #'cuStateVec_enable': True,   # NVIDIA library optimization [9]\n",
    "        #'batched_shots_gpu': True,   # Parallelize batch on GPU [9]\n",
    "        #'blocking_enable': False,     # Disable chunking; simulation fits in VRAM \n",
    "        #'seed_simulator': train_config['seed']\n",
    "    }\n",
    "}\n",
    "\n",
    "# # Save account\n",
    "# QiskitRuntimeService.save_account(\n",
    "#     token=\"\",\n",
    "#     instance=\"crn:v1:bluemix:public:quantum-computing:eu-de:a/cb804b30dfcb48b890393bfd6e41e9c2:4cb40c64-a531-4c13-b39c-e04c31185259::\",\n",
    "#     set_as_default = True,\n",
    "#     overwrite=True\n",
    "# )\n",
    "\n",
    "def reset_backend():\n",
    "    service = QiskitRuntimeService(channel=backend_config['channel'])\n",
    "    real_backend = service.backend(backend_config['name']) #backend = service.least_busy(min_num_qubits=30)\n",
    "\n",
    "    backend = AerSimulator.from_backend(real_backend, **backend_config['sim_options']) # Get current backend state\n",
    "    #backend.set_options(seed_simulator=train_config['seed']) RANDOM STATE? TODO\n",
    "    #backend.set_options(**backend_config['sim_options'])\n",
    "\n",
    "    backend_dict = {\n",
    "        'timestamp': dt.datetime.now(dt.timezone.utc),\n",
    "        'configuration': real_backend.configuration().to_dict(),\n",
    "        'options': backend.options,\n",
    "        'properties': real_backend.properties().to_dict(),\n",
    "        'target': real_backend.target_history(),\n",
    "        'noise_model': NoiseModel.from_backend(real_backend),\n",
    "    }\n",
    "\n",
    "    # # Example for simulator backend\n",
    "    # backend_dict = {\n",
    "    #     'timestamp': dt.datetime.now(dt.timezone.utc),\n",
    "    #     'configuration': backend.configuration().to_dict(),\n",
    "    #     'options': backend.options, # Options object saved directly\n",
    "    #     'properties': backend.properties().to_dict(),\n",
    "    #     'target': backend.target, # Target object saved directly\n",
    "    #     'noise_model': NoiseModel.from_backend(backend),\n",
    "    #     'sim_options': {'shots': 1024}\n",
    "    #\n",
    "    #     # With timestamp\n",
    "    #      'target_h': real_backend.target_history(datetime=backend_config['timestamp']),\n",
    "    #      'noise_model_h': NoiseModel.from_backend_properties(real_backend.properties(datetime=backend_config['timestamp'])), # No functiona: error por falta de datos en properties\n",
    "    # }\n",
    "\n",
    "    # Save to a single .pkl file\n",
    "    with open(train_config['backend_file'], \"wb\") as f:\n",
    "        pickle.dump(backend_dict, f)\n",
    "\n",
    "\n",
    "\n",
    "if train_config['execution_type'] == \"real_hardware\":\n",
    "    service = QiskitRuntimeService(channel=backend_config['channel']) # Execution in real hardware\n",
    "    backend = service.backend(backend_config['name']) #backend = service.least_busy(min_num_qubits=30)\n",
    "\n",
    "    pm = generate_preset_pass_manager(optimization_level=3, backend=backend)\n",
    "\n",
    "    session = Session(backend=backend)\n",
    "    precision = 0.015625\n",
    "    estimator = EstimatorV2_rh(mode=session, options=EstimatorOptions(precision=precision))\n",
    "\n",
    "elif train_config['execution_type'] == \"noisy_simulation\":\n",
    "    # Load backend configuration\n",
    "    try:\n",
    "        with open(train_config['backend_file'], \"rb\") as f:\n",
    "            backend_dict = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Backend data file not found. Resetting backend configuration.\")\n",
    "        reset_backend()\n",
    "        with open(train_config['backend_file'], \"rb\") as f:\n",
    "            backend_dict = pickle.load(f)\n",
    "\n",
    "    backend = AerSimulator(\n",
    "        configuration=AerBackendConfiguration.from_dict(backend_dict['configuration']),\n",
    "        properties=AerBackendProperties.from_dict(backend_dict['properties']),\n",
    "        target = backend_dict['target'],\n",
    "        **backend_dict['options']\n",
    "    )\n",
    "\n",
    "    pm = generate_preset_pass_manager(optimization_level=3, backend=backend)\n",
    "\n",
    "    precision = 0.015625\n",
    "    estimator = EstimatorV2_sim(\n",
    "        options = {\n",
    "            \"default_precision\": precision,\n",
    "            #'seed_estimator': train_config['seed'],\n",
    "            \"backend_options\": backend_config['sim_options'],\n",
    "            \"run_options\": {} #TODO configurar mejor?\n",
    "        })\n",
    "\n",
    "else:\n",
    "    backend = AerSimulator(**backend_config['sim_options'])\n",
    "\n",
    "    precision = 0.0\n",
    "    estimator = EstimatorV2_sim(\n",
    "        options = {\n",
    "            \"default_precision\": precision,\n",
    "            #'seed_estimator': train_config['seed'],\n",
    "            \"backend_options\": backend_config['sim_options'],\n",
    "            \"run_options\": {} #TODO configurar mejor?\n",
    "        })\n",
    "\n",
    "    #pm = generate_preset_pass_manager(optimization_level=3, backend=backend)\n",
    "    pm = None\n",
    "\n",
    "\n",
    "# # Select device torch? Yata en sim_options no? TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ec31ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuits file not found. Creating new circuits file.\n"
     ]
    }
   ],
   "source": [
    "#- Create quantum circuits -#\n",
    "\n",
    "# Create real data sample circuit\n",
    "def generate_real_circuit():\n",
    "    n_qubits = train_config['n_qubits']\n",
    "\n",
    "    # sv = random_statevector(2**N_QUBITS, seed=SEED)\n",
    "    # qc = QuantumCircuit(N_QUBITS)\n",
    "    # qc.prepare_state(sv, qc.qubits, normalize=True)\n",
    "\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    qc.h(range(n_qubits-1))\n",
    "    qc.cx(n_qubits-2, n_qubits-1)\n",
    "    return qc\n",
    "\n",
    "\n",
    "# Create generator\n",
    "def generate_generator():\n",
    "    n_qubits = train_config['n_qubits']\n",
    "\n",
    "    qc = RealAmplitudes(n_qubits,\n",
    "                        reps=3, # Number of layers\n",
    "                        parameter_prefix='θ_g',\n",
    "                        name='Generator')\n",
    "    \n",
    "    return qc.decompose()\n",
    "\n",
    "\n",
    "# Create discriminator\n",
    "def generate_discriminator():\n",
    "    n_qubits = train_config['n_qubits']\n",
    "\n",
    "    qc = EfficientSU2(n_qubits,\n",
    "                      entanglement=\"reverse_linear\",\n",
    "                      reps=1, # Number of layers\n",
    "                      parameter_prefix='θ_d',\n",
    "                      name='Discriminator').decompose()\n",
    "\n",
    "\n",
    "    param_index = qc.num_parameters\n",
    "\n",
    "    for i in reversed(range(n_qubits - 1)):\n",
    "        qc.cx(i, n_qubits - 1)\n",
    "\n",
    "    #qc.rx(disc_weights[param_index], N_QUBITS-1); param_index += 1\n",
    "    qc.ry(Parameter(\"θ_d[\"+str(param_index)+\"]\"), n_qubits-1); param_index += 1\n",
    "    qc.rz(Parameter(\"θ_d[\"+str(param_index)+\"]\"), n_qubits-1); param_index += 1\n",
    "    \n",
    "    return qc\n",
    "\n",
    "\n",
    "# Create quantum circuits\n",
    "def create_circuits():\n",
    "    real_circuit = generate_real_circuit()\n",
    "    generator_circuit = generate_generator()\n",
    "    discriminator_circuit = generate_discriminator()\n",
    "\n",
    "    with open(train_config['circuits_file'], 'wb') as fd:\n",
    "        qpy.dump([real_circuit, generator_circuit, discriminator_circuit], fd)\n",
    "\n",
    "# Load circuits\n",
    "if train_config['create_circuits']:\n",
    "    create_circuits()\n",
    "\n",
    "try:\n",
    "    with open(train_config['circuits_file'], 'rb') as fd:\n",
    "        circuits = qpy.load(fd)\n",
    "except FileNotFoundError:\n",
    "    print(\"Circuits file not found. Creating new circuits file.\")\n",
    "    create_circuits()\n",
    "    with open(train_config['circuits_file'], 'rb') as fd:\n",
    "        circuits = qpy.load(fd)\n",
    "    \n",
    "real_circuit = circuits[0]\n",
    "generator_circuit = circuits[1]\n",
    "discriminator_circuit = circuits[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a49ba77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Set up training quantum circuits -#\n",
    "def generate_training_circuits(real_circuit, generator_circuit, discriminator_circuit):\n",
    "    n_qubits = train_config['n_qubits']\n",
    "\n",
    "    # Connect real data and discriminator\n",
    "    real_disc_circuit = QuantumCircuit(n_qubits)\n",
    "    real_disc_circuit.compose(real_circuit, inplace=True)\n",
    "    real_disc_circuit.compose(discriminator_circuit, inplace=True)\n",
    "\n",
    "    # Connect generator and discriminator\n",
    "    gen_disc_circuit = QuantumCircuit(n_qubits)\n",
    "    gen_disc_circuit.compose(generator_circuit, inplace=True)\n",
    "    gen_disc_circuit.compose(discriminator_circuit, inplace=True)\n",
    "\n",
    "    # Gradient computation method\n",
    "    if train_config['gradient_method'] == 'SPSA':\n",
    "        gradient = SPSAEstimatorGradient(estimator=estimator)\n",
    "    elif train_config['gradient_method'] == 'REG':\n",
    "        gradient = ReverseEstimatorGradient()\n",
    "    else:\n",
    "        gradient = ParamShiftEstimatorGradient(estimator=estimator)\n",
    "\n",
    "    # Observables\n",
    "    H1 = SparsePauliOp.from_list([(\"Z\" + \"I\"*(n_qubits-1), 1.0)])\n",
    "    N_DPARAMS = discriminator_circuit.num_parameters\n",
    "\n",
    "    # specify QNN to update generator parameters\n",
    "    gen_qnn = EstimatorQNN(circuit=gen_disc_circuit,\n",
    "                        input_params=gen_disc_circuit.parameters[:N_DPARAMS], # fixed parameters (discriminator parameters)\n",
    "                        weight_params=gen_disc_circuit.parameters[N_DPARAMS:], # parameters to update (generator parameters)\n",
    "                        estimator=estimator,\n",
    "                        observables=[H1],\n",
    "                        gradient=gradient,\n",
    "                        default_precision=precision,\n",
    "                        pass_manager=pm\n",
    "                        )\n",
    "\n",
    "    # specify QNN to update discriminator parameters regarding to fake data\n",
    "    disc_fake_qnn = EstimatorQNN(circuit=gen_disc_circuit,\n",
    "                            input_params=gen_disc_circuit.parameters[N_DPARAMS:], # fixed parameters (generator parameters)\n",
    "                            weight_params=gen_disc_circuit.parameters[:N_DPARAMS], # parameters to update (discriminator parameters)\n",
    "                            estimator=estimator,\n",
    "                            observables=[H1],\n",
    "                            gradient=gradient,\n",
    "                            default_precision=precision,\n",
    "                            pass_manager=pm\n",
    "                            )\n",
    "\n",
    "    # specify QNN to update discriminator parameters regarding to real data\n",
    "    disc_real_qnn = EstimatorQNN(circuit=real_disc_circuit,\n",
    "                            input_params=[], # no input parameters\n",
    "                            weight_params=gen_disc_circuit.parameters[:N_DPARAMS], # parameters to update (discriminator parameters)\n",
    "                            estimator=estimator,\n",
    "                            observables=[H1],\n",
    "                            gradient=gradient,\n",
    "                            default_precision=precision,\n",
    "                            pass_manager=pm\n",
    "                            )\n",
    "    \n",
    "    return gen_qnn, disc_fake_qnn, disc_real_qnn\n",
    "\n",
    "gen_qnn, disc_fake_qnn, disc_real_qnn = generate_training_circuits(real_circuit, generator_circuit, discriminator_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d59eeb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file not found. Resetting parameters.\n"
     ]
    }
   ],
   "source": [
    "#- Restore parameters and model states -#\n",
    "\n",
    "# Reset all data training\n",
    "def reset_data(n_gen_params, n_disc_params):\n",
    "    np.random.seed(train_config['seed'])\n",
    "\n",
    "    init_gen_params = np.random.uniform(low=-np.pi, high=np.pi, size=(n_gen_params,))\n",
    "    init_disc_params = np.random.uniform(low=-np.pi, high=np.pi, size=(n_disc_params,))\n",
    "\n",
    "    gen_params = torch.tensor(init_gen_params, requires_grad=True, dtype = torch.float32)\n",
    "    disc_params = torch.tensor(init_disc_params, requires_grad=True, dtype = torch.float32)\n",
    "\n",
    "    optimizer_g = torch.optim.Adam([gen_params], lr=0.005)\n",
    "    optimizer_d = torch.optim.Adam([disc_params], lr=0.005)\n",
    "\n",
    "    torch.save({\n",
    "        'init_gen_params': init_gen_params,\n",
    "        'init_disc_params': init_disc_params,\n",
    "        'gen_params': gen_params,\n",
    "        'disc_params': disc_params,\n",
    "        'best_gen_params': init_gen_params,\n",
    "        'optimizer_g_state': optimizer_g.state_dict(),\n",
    "        'optimizer_d_state': optimizer_d.state_dict(),\n",
    "        'current_epoch': 0,\n",
    "        \"metrics\": {\n",
    "            \"gloss\": {},\n",
    "            \"dloss\": {},\n",
    "            \"kl_div\": {},\n",
    "        },\n",
    "        'random_state': np.random.get_state()\n",
    "    }, train_config['training_data_file'])\n",
    "\n",
    "\n",
    "# Load parameters and training states\n",
    "if train_config['reset_data']:\n",
    "    reset_data(generator_circuit.num_parameters, discriminator_circuit.num_parameters)\n",
    "\n",
    "try:\n",
    "    params = torch.load(train_config['training_data_file'], weights_only=False)\n",
    "except FileNotFoundError:\n",
    "    print(\"Training data file not found. Resetting parameters.\")\n",
    "    reset_data(generator_circuit.num_parameters, discriminator_circuit.num_parameters)\n",
    "    params = torch.load(train_config['training_data_file'], weights_only=False)\n",
    "\n",
    "np.random.set_state(params['random_state'])\n",
    "\n",
    "gen_params = params['gen_params']\n",
    "disc_params = params['disc_params']\n",
    "\n",
    "optimizer_g = torch.optim.Adam([gen_params])\n",
    "optimizer_d = torch.optim.Adam([disc_params])\n",
    "\n",
    "optimizer_g.load_state_dict(params['optimizer_g_state'])\n",
    "optimizer_d.load_state_dict(params['optimizer_d_state'])\n",
    "\n",
    "current_epoch = params['current_epoch']\n",
    "gloss = params['metrics']['gloss']\n",
    "gen_loss = list(gloss)[-1] if (gloss) else None\n",
    "dloss = params['metrics']['dloss']\n",
    "disc_loss = list(dloss)[-1] if (dloss) else None\n",
    "kl_div = params['metrics']['kl_div']\n",
    "min_kl_div = np.min(list(kl_div.values())) if (kl_div) else float('inf')\n",
    "best_gen_params = params['best_gen_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "837b50cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Manage training interruption -#\n",
    "\n",
    "# Class to manage training interruption\n",
    "class Interrupter:\n",
    "    def __init__(self):\n",
    "        self.kill_now = False\n",
    "        self.interrupt_count = 0\n",
    "\n",
    "        # Intercept the Ctrl+C signal\n",
    "        signal.signal(signal.SIGINT, self.handle_signal)\n",
    "        # Intercept the termination signal (useful for Docker/systems)\n",
    "        #signal.signal(signal.SIGTERM, self.handle_signal)\n",
    "\n",
    "    def handle_signal(self, signum, frame):\n",
    "        self.interrupt_count += 1\n",
    "        \n",
    "        if self.interrupt_count == 1:\n",
    "            # First Press: Enable graceful exit\n",
    "            self.kill_now = True\n",
    "            print(\"\\nInterrupter: Termination signal received. The loop will stop after the current iteration. (Press Ctrl+C again to force quit)\")\n",
    "        \n",
    "        elif self.interrupt_count >= 2:\n",
    "            # Second Press: Force quit immediately\n",
    "            print(\"\\nInterrupter: [!] Force quit triggered! Terminating immediately.\")\n",
    "            # Restore default signal handler to avoid recursion\n",
    "            signal.signal(signal.SIGINT, signal.SIG_DFL)\n",
    "            # Raise the exception to stop execution right here\n",
    "            raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38f0ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of qubits of the circuit (156) does not match the number of qubits of the ()-th observable (4).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdisc_fake_qnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisc_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit_machine_learning/neural_networks/neural_network.py:229\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    227\u001b[0m input_, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(input_data)\n\u001b[1;32m    228\u001b[0m weights_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_weights(weights)\n\u001b[0;32m--> 229\u001b[0m output_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_forward_output(output_data, shape)\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py:301\u001b[0m, in \u001b[0;36mEstimatorQNN._forward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    298\u001b[0m         circuit_observable_params\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circuit, observable, parameter_values_))\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# For BaseEstimatorV2, run the estimator using PUBs and specified precision\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit_observable_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_precision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     results \u001b[38;5;241m=\u001b[39m [result\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mevs \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m job\u001b[38;5;241m.\u001b[39mresult()]\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit_aer/primitives/estimator_v2.py:95\u001b[0m, in \u001b[0;36mEstimatorV2.run\u001b[0;34m(self, pubs, precision)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mdefault_precision\n\u001b[0;32m---> 95\u001b[0m coerced_pubs \u001b[38;5;241m=\u001b[39m [EstimatorPub\u001b[38;5;241m.\u001b[39mcoerce(pub, precision) \u001b[38;5;28;01mfor\u001b[39;00m pub \u001b[38;5;129;01min\u001b[39;00m pubs]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_pubs(coerced_pubs)\n\u001b[1;32m     97\u001b[0m job \u001b[38;5;241m=\u001b[39m PrimitiveJob(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, coerced_pubs)\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit_aer/primitives/estimator_v2.py:95\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mdefault_precision\n\u001b[0;32m---> 95\u001b[0m coerced_pubs \u001b[38;5;241m=\u001b[39m [\u001b[43mEstimatorPub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pub \u001b[38;5;129;01min\u001b[39;00m pubs]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_pubs(coerced_pubs)\n\u001b[1;32m     97\u001b[0m job \u001b[38;5;241m=\u001b[39m PrimitiveJob(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, coerced_pubs)\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit/primitives/containers/estimator_pub.py:162\u001b[0m, in \u001b[0;36mEstimatorPub.coerce\u001b[0;34m(cls, pub, precision)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pub) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pub[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     precision \u001b[38;5;241m=\u001b[39m pub[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameter_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit/primitives/containers/estimator_pub.py:85\u001b[0m, in \u001b[0;36mEstimatorPub.__init__\u001b[0;34m(self, circuit, observables, parameter_values, precision, validate)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe observables shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservables\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter values shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameter_values\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are not broadcastable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit/primitives/containers/estimator_pub.py:188\u001b[0m, in \u001b[0;36mEstimatorPub.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m     num_qubits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(observable)))\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcircuit\u001b[38;5;241m.\u001b[39mnum_qubits \u001b[38;5;241m!=\u001b[39m num_qubits:\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of qubits of the circuit (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcircuit\u001b[38;5;241m.\u001b[39mnum_qubits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) does \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot match the number of qubits of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-th observable (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_qubits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Cross validate circuits and parameter_values\u001b[39;00m\n\u001b[1;32m    194\u001b[0m num_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameter_values\u001b[38;5;241m.\u001b[39mnum_parameters\n",
      "\u001b[0;31mValueError\u001b[0m: The number of qubits of the circuit (156) does not match the number of qubits of the ()-th observable (4)."
     ]
    }
   ],
   "source": [
    "disc_fake_qnn.forward(gen_params.detach(), disc_params.detach())[0,0] #TODO transpile circuits and observables before executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720bb9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | Generator cost | Discriminator cost | KL Div. | Best KL Div. | Time |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 24\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (disc_train_step \u001b[38;5;241m==\u001b[39m D_STEPS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (epoch \u001b[38;5;241m%\u001b[39m C_STEPS \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m     value_dcost_fake \u001b[38;5;241m=\u001b[39m \u001b[43mdisc_fake_qnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisc_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m     value_dcost_real \u001b[38;5;241m=\u001b[39m disc_real_qnn\u001b[38;5;241m.\u001b[39mforward([], disc_params\u001b[38;5;241m.\u001b[39mdetach())[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit_machine_learning/neural_networks/neural_network.py:229\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    228\u001b[0m weights_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_weights(weights)\n\u001b[0;32m--> 229\u001b[0m output_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_forward_output(output_data, shape)\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py:301\u001b[0m, in \u001b[0;36mEstimatorQNN._forward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# For BaseEstimatorV2, run the estimator using PUBs and specified precision\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit_observable_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_precision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m results \u001b[38;5;241m=\u001b[39m [result\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mevs \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m job\u001b[38;5;241m.\u001b[39mresult()]\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit_aer/primitives/estimator_v2.py:95\u001b[0m, in \u001b[0;36mEstimatorV2.run\u001b[0;34m(self, pubs, precision)\u001b[0m\n\u001b[1;32m     94\u001b[0m     precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mdefault_precision\n\u001b[0;32m---> 95\u001b[0m coerced_pubs \u001b[38;5;241m=\u001b[39m [EstimatorPub\u001b[38;5;241m.\u001b[39mcoerce(pub, precision) \u001b[38;5;28;01mfor\u001b[39;00m pub \u001b[38;5;129;01min\u001b[39;00m pubs]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_pubs(coerced_pubs)\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit_aer/primitives/estimator_v2.py:95\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     94\u001b[0m     precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mdefault_precision\n\u001b[0;32m---> 95\u001b[0m coerced_pubs \u001b[38;5;241m=\u001b[39m [\u001b[43mEstimatorPub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pub \u001b[38;5;129;01min\u001b[39;00m pubs]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_pubs(coerced_pubs)\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit/primitives/containers/estimator_pub.py:162\u001b[0m, in \u001b[0;36mEstimatorPub.coerce\u001b[0;34m(cls, pub, precision)\u001b[0m\n\u001b[1;32m    160\u001b[0m     precision \u001b[38;5;241m=\u001b[39m pub[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameter_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit/primitives/containers/estimator_pub.py:85\u001b[0m, in \u001b[0;36mEstimatorPub.__init__\u001b[0;34m(self, circuit, observables, parameter_values, precision, validate)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/qiskit/primitives/containers/estimator_pub.py:188\u001b[0m, in \u001b[0;36mEstimatorPub.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcircuit\u001b[38;5;241m.\u001b[39mnum_qubits \u001b[38;5;241m!=\u001b[39m num_qubits:\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of qubits of the circuit (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcircuit\u001b[38;5;241m.\u001b[39mnum_qubits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) does \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot match the number of qubits of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-th observable (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_qubits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Cross validate circuits and parameter_values\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of qubits of the circuit (156) does not match the number of qubits of the ()-th observable (4).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 110\u001b[0m\n\u001b[1;32m     92\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_gen_params\u001b[39m\u001b[38;5;124m'\u001b[39m: params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_gen_params\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_disc_params\u001b[39m\u001b[38;5;124m'\u001b[39m: params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_disc_params\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mget_state()\n\u001b[1;32m    107\u001b[0m }, train_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_data_file\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    109\u001b[0m kl_div_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(kl_div\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   Data path:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_data_file\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   Best KLDiv:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkl_div_data\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39margmin(kl_div_data), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   Improvement:\u001b[39m\u001b[38;5;124m\"\u001b[39m, kl_div_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmin(kl_div_data))\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:3302\u001b[0m, in \u001b[0;36mmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3190\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_min_dispatcher)\n\u001b[1;32m   3191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   3192\u001b[0m         where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   3193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3194\u001b[0m \u001b[38;5;124;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   3195\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3300\u001b[0m \u001b[38;5;124;03m    6\u001b[39;00m\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3303\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-ibm-new/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "#- Training -#\n",
    "\n",
    "D_STEPS = train_config['disc_iterations']\n",
    "G_STEPS = train_config['gen_iterations']\n",
    "C_STEPS = train_config['save_loss_iterations']\n",
    "\n",
    "real_distribution_tensor = torch.from_numpy(Statevector(real_circuit).probabilities()) # Retrieve real data probability distribution \n",
    "\n",
    "interrupter = Interrupter()\n",
    "\n",
    "if train_config['print_progress_iterations']:\n",
    "    TABLE_HEADERS = \"Epoch | Generator cost | Discriminator cost | KL Div. | Best KL Div. | Time |\"\n",
    "    print(TABLE_HEADERS)\n",
    "start_time = time.time()\n",
    "\n",
    "#--- Training loop ---#\n",
    "try: # In case of interruption\n",
    "    for epoch in range(current_epoch, train_config['max_iterations']+1):\n",
    "\n",
    "        #--- Quantum discriminator parameter updates ---#\n",
    "        for disc_train_step in range(D_STEPS):\n",
    "            # Calculate discriminator cost\n",
    "            if (disc_train_step == D_STEPS-1) and (epoch % C_STEPS == 0):\n",
    "                value_dcost_fake = disc_fake_qnn.forward(gen_params.detach(), disc_params.detach())[0,0]\n",
    "                value_dcost_real = disc_real_qnn.forward([], disc_params.detach())[0,0]\n",
    "                disc_loss = ((value_dcost_real - value_dcost_fake)-2)/4\n",
    "                dloss[epoch] = disc_loss\n",
    "\n",
    "            # Caltulate discriminator gradient\n",
    "            grad_dcost_fake = disc_fake_qnn.backward(gen_params.detach(), disc_params.detach())[1][0,0]\n",
    "            grad_dcost_real = disc_real_qnn.backward([], disc_params.detach())[1][0,0]\n",
    "            grad_dcost = grad_dcost_real - grad_dcost_fake\n",
    "            grad_dcost = torch.tensor(grad_dcost, dtype = torch.float32)\n",
    "            \n",
    "            # Update discriminator parameters\n",
    "            optimizer_d.zero_grad()\n",
    "            disc_params.grad = grad_dcost.to(dtype=disc_params.dtype, device=disc_params.device)\n",
    "            optimizer_d.step()\n",
    "\n",
    "        #--- Quantum generator parameter updates ---#\n",
    "        for gen_train_step in range(G_STEPS):\n",
    "            # Calculate generator cost\n",
    "            if (gen_train_step == G_STEPS-1) and (epoch % C_STEPS == 0):\n",
    "                value_gcost = gen_qnn.forward(disc_params.detach(), gen_params.detach())[0,0]\n",
    "                gen_loss = (value_gcost-1)/2\n",
    "                gloss[epoch] = gen_loss\n",
    "\n",
    "            # Calculate generator gradient\n",
    "            grad_gcost = gen_qnn.backward(disc_params.detach(), gen_params.detach())[1][0,0]\n",
    "            grad_gcost = torch.tensor(grad_gcost, dtype = torch.float32)\n",
    "\n",
    "            # Update generator parameters\n",
    "            optimizer_g.zero_grad()\n",
    "            gen_params.grad = grad_gcost.to(dtype=gen_params.dtype, device=gen_params.device)\n",
    "            optimizer_g.step()\n",
    "\n",
    "\n",
    "        #--- Track KL and save best performing generator weights ---#\n",
    "        gen_distribution_tensor = torch.from_numpy(Statevector(generator_circuit.assign_parameters(gen_params.detach().numpy())).probabilities()) # Retrieve probability distribution of generator with current parameters.\n",
    "\n",
    "        # 3. Move to GPU (The speedup for large vectors is massive) # TODO\n",
    "        # if torch.cuda.is_available():\n",
    "        #     p = p.cuda()\n",
    "        #     q = q.cuda()\n",
    "\n",
    "        # Performance measurement function: uses Kullback Leibler Divergence to measures the distance between two distributions\n",
    "        current_kl = torch.nn.functional.kl_div(input=gen_distribution_tensor.log(), target=real_distribution_tensor, reduction='sum').numpy() # reduction=\"batchnoseque\" pa batches\n",
    "        kl_div[epoch] = current_kl\n",
    "        if min_kl_div > current_kl:\n",
    "            min_kl_div = current_kl\n",
    "            best_gen_params = gen_params.detach().numpy() # New best\n",
    "\n",
    "\n",
    "        #--- Print progress ---#\n",
    "        if train_config['print_progress_iterations'] and (epoch % train_config['print_progress_iterations'] == 0):\n",
    "            for header, val in zip(TABLE_HEADERS.split('|'),\n",
    "                                (epoch, gen_loss, disc_loss, current_kl, min_kl_div, (time.time() - start_time))):\n",
    "                print(f\"{val:.3g} \".rjust(len(header)), end=\"|\")\n",
    "            start_time = time.time()\n",
    "            print()\n",
    "\n",
    "        # In case of interruption\n",
    "        if interrupter.kill_now:\n",
    "            print(\"Interrupter: Graceful exit triggered. Breaking loop.\")\n",
    "            break\n",
    "            \n",
    "#--- Save parameters and optimizer states data ---#\n",
    "finally:\n",
    "    if train_config['execution_type'] == \"real_hardware\":\n",
    "        session.close()\n",
    "    \n",
    "    torch.save({\n",
    "        'init_gen_params': params['init_gen_params'],\n",
    "        'init_disc_params': params['init_disc_params'],\n",
    "        'best_gen_params': best_gen_params,\n",
    "        'gen_params': gen_params,\n",
    "        'disc_params': disc_params,\n",
    "        'optimizer_g_state': optimizer_g.state_dict(),\n",
    "        'optimizer_d_state': optimizer_d.state_dict(),\n",
    "        'current_epoch': epoch+1,\n",
    "        \"metrics\": {\n",
    "            \"gloss\": gloss,\n",
    "            \"dloss\": dloss,\n",
    "            \"kl_div\": kl_div,\n",
    "        },\n",
    "        'random_state': np.random.get_state()\n",
    "    }, train_config['training_data_file'])\n",
    "    \n",
    "    kl_div_data = list(kl_div.values())\n",
    "    print(\"Training complete:\", \"\\n   Data path:\", train_config['training_data_file'], \"\\n   Best KLDiv:\", np.min(kl_div_data), \"in epoch\", np.argmin(kl_div_data), \"\\n   Improvement:\", kl_div_data[0]-np.min(kl_div_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431d5b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gradient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit_machine_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchConnector\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# --- 3. QNN Definition ---\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# The EstimatorQNN now uses the optimized backend and gradient method.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Ensure 'input_params' and 'weight_params' are defined as per your circuit.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m qnn_g \u001b[38;5;241m=\u001b[39m EstimatorQNN(\n\u001b[1;32m     13\u001b[0m     circuit\u001b[38;5;241m=\u001b[39mgenerator_circuit,\n\u001b[1;32m     14\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mbackend,\n\u001b[0;32m---> 15\u001b[0m     gradient\u001b[38;5;241m=\u001b[39m\u001b[43mgradient\u001b[49m, \n\u001b[1;32m     16\u001b[0m     input_params\u001b[38;5;241m=\u001b[39minput_params,   \u001b[38;5;66;03m# Assuming these are defined\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     weight_params\u001b[38;5;241m=\u001b[39mweight_params\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# TorchConnector handles the integration with PyTorch's autograd\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model_g \u001b[38;5;241m=\u001b[39m TorchConnector(qnn_g)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gradient' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from qiskit import transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_algorithms.gradients import ReverseEstimatorGradient\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# --- 3. QNN Definition ---\n",
    "# The EstimatorQNN now uses the optimized backend and gradient method.\n",
    "# Ensure 'input_params' and 'weight_params' are defined as per your circuit.\n",
    "qnn_g = EstimatorQNN(\n",
    "    circuit=generator_circuit,\n",
    "    estimator=backend,\n",
    "    gradient=gradient, \n",
    "    input_params=input_params,   # Assuming these are defined\n",
    "    weight_params=weight_params\n",
    ")\n",
    "# TorchConnector handles the integration with PyTorch's autograd\n",
    "model_g = TorchConnector(qnn_g)\n",
    "\n",
    "# --- 4. Pre-compilation for KL Divergence Tracking ---\n",
    "# Instead of instantiating Statevector() every loop, we pre-transpile\n",
    "# a circuit that explicitly saves probabilities.\n",
    "prob_circuit = generator_circuit.copy()\n",
    "prob_circuit.save_probabilities() # GPU-native instruction [8]\n",
    "transpiled_prob_circ = transpile(prob_circuit, backend)\n",
    "\n",
    "# --- 5. Optimized Training Loop ---\n",
    "for epoch in range(current_epoch, train_config['max_iterations']+1):\n",
    "\n",
    "    # --- Quantum Discriminator Updates ---\n",
    "    for disc_train_step in range(D_STEPS):\n",
    "        # Optimization: Ensure closure_d handles batching correctly\n",
    "        disc_loss = optimizer_d.step(closure_d)\n",
    "        if (disc_train_step == D_STEPS-1):\n",
    "            dloss[epoch] = disc_loss.detach().cpu().numpy()\n",
    "\n",
    "    # --- Quantum Generator Updates ---\n",
    "    for gen_train_step in range(G_STEPS):\n",
    "        # The optimizer uses ReverseEstimatorGradient implicitly via model_g\n",
    "        gen_loss = optimizer_g.step(closure_g)\n",
    "        if (gen_train_step == G_STEPS-1):\n",
    "            gloss[epoch] = gen_loss.detach().cpu().numpy()\n",
    "\n",
    "    # --- Optimized KL Tracking ---\n",
    "    # We avoid creating a new simulation instance. We run the pre-transpiled\n",
    "    # circuit on the persistent GPU backend.\n",
    "    with torch.no_grad():\n",
    "        # Get current weights efficiently\n",
    "        gen_params_tensor = torch.nn.utils.parameters_to_vector(model_g.parameters())\n",
    "        gen_params_np = gen_params_tensor.cpu().numpy()\n",
    "        \n",
    "        # Execute on GPU backend; retrieve only small probability vector\n",
    "        # parameter_binds maps the circuit parameters to the current numpy weights\n",
    "        job = backend.run(\n",
    "            transpiled_prob_circ, \n",
    "            parameter_binds=[{p: v for p, v in zip(prob_circuit.parameters, gen_params_np)}]\n",
    "        )\n",
    "        result = job.result()\n",
    "        \n",
    "        # Data transfer is minimal: 2^N floats instead of complex statevector\n",
    "        probs_np = result.data(0)['probabilities'] \n",
    "        \n",
    "        # Compute KL using PyTorch (can be done on GPU if tensors are moved there)\n",
    "        gen_distribution_tensor = torch.from_numpy(probs_np)\n",
    "        current_kl = torch.nn.functional.kl_div(\n",
    "            input=gen_distribution_tensor.log(), \n",
    "            target=real_distribution_tensor, \n",
    "            reduction='sum'\n",
    "        ).item()\n",
    "        \n",
    "        kl_div[epoch] = current_kl\n",
    "        \n",
    "        if min_kl_div > current_kl:\n",
    "            min_kl_div = current_kl\n",
    "            best_gen_params = gen_params_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3756c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07614865276264027 -0.24768847867380828 [ 1.88213447e-01  2.54346660e-02 -3.53355673e-01 -4.06557016e-01\n",
      " -6.80829957e-02  1.56869657e-01  9.21908102e-02 -2.92552537e-02\n",
      "  1.04670972e-01  3.23729215e-01 -2.51169527e-01  9.26615763e-02\n",
      " -2.77555756e-17  6.07153217e-17 -5.55111512e-17  1.60215298e-01\n",
      "  4.40572509e-01  2.77555756e-17] [ 1.01028582e-01 -1.82956686e-01 -4.54795341e-02  4.54795341e-02\n",
      " -1.42755927e-01  1.64926736e-01 -2.84142196e-01 -3.47703140e-01\n",
      " -6.73684881e-02  8.70879370e-02 -4.63491040e-01  3.38541303e-01\n",
      " -8.32667268e-17 -1.38777878e-17  8.32667268e-17  1.04554093e-01\n",
      " -1.10651408e-01  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "value_dcost_fake = disc_fake_qnn.forward(gen_params.detach(), disc_params.detach())[0,0]\n",
    "value_dcost_real = disc_real_qnn.forward([], disc_params.detach())[0,0]\n",
    "\n",
    "\n",
    "grad_dcost_fake = disc_fake_qnn.backward(gen_params.detach(), disc_params.detach())[1][0,0]\n",
    "grad_dcost_real = disc_real_qnn.backward([], disc_params.detach())[1][0,0]\n",
    "\n",
    "\n",
    "print(value_dcost_fake, value_dcost_real, grad_dcost_fake, grad_dcost_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92669eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_circuit = generator_circuit.copy()\n",
    "prob_circuit.save_probabilities() # GPU-native instruction [8]\n",
    "transpiled_prob_circ = transpile(prob_circuit, backend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit-ibm-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
